<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

    Wanxin Jin


</title>
<meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸŒŸ</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->






    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="http://localhost:4000/">
       <span class="font-weight-bold"></span>   Wanxin Jin
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                Publications
                
              </a>
          </li>
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/teaching/">
                Teaching
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/videos/">
                Videos
                
              </a>
          </li>
          
          
          
          
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">
     <span class="font-weight-bold"></span>  Wanxin Jin
    </h1>
     <p class="desc"></p>
  </header>

  <article>
    
    <div class="profile float-right">
      
        <img class="img-fluid z-depth-1 rounded" src="/assets/img/WanxinJIN2.jpg">
      
      
        <div class="address">
          
        </div>
      
    </div>
    

    <div class="clearfix">
      <p>I am a postdoctoral researcher in the <a href="https://www.grasp.upenn.edu/" target="_blank">GRASP Laboratory</a> at <a href="https://www.upenn.edu/" target="_blank">University of Pennsylvania</a>, working with <a href="https://dair.seas.upenn.edu/" target="_blank">Prof. Michael Posa</a>.</p>

<p>I obtained my Ph.D. in the area of Autonomy and Control in the <a href="https://engineering.purdue.edu/AAE" target="_blank">School of Aeronautics and Astronautics</a>, <a href="https://www.purdue.edu/" target="_blank">Purdue University</a> in July 2021. Prior to Purdue,  I worked as a research assistant  at <a href="https://www.tum.de/en/" target="_blank">Technical University of Munich</a>, Germany. I  obtained my   Master and Bachelor degrees in Control Science and Engineering from <a href="http://en.hit.edu.cn/" target="_blank">Harbin Institute of Technology</a>, China.</p>

<p align="center">
<a href="mailto:wanxinjin@gmail.com" target="_blank">Email</a> / 
<a href="https://github.com/wanxinjin" target="_blank">Github</a> / 
<a href="https://twitter.com/jinwanxin" target="_blank">Twitter</a> / 
<a href="https://scholar.google.com/citations?user=SoEC4h4AAAAJ&amp;hl=en" target="_blank">Google Scholar</a> 
</p>

<p style="margin-bottom:0.8cm; margin-left: 0.5cm"> </p>

<hr />

<h3 id="research-interests">Research Interests</h3>
<p>My research lies at the intersection of control, machine learning, and optimization, with emphasis on addressing the fundamental and pressing challenges in autonomous systems and human-robot systems.</p>

<body>
  <div style="width: 100%;">
      <div style="width: 18%; height: 100px; float: left; background: transparent;"> 
         <strong>Control + Learning</strong>
      </div>
      <div style="margin-left: 18%; height: 100px; background: transparent;"> 
          <ul>
            <li>Differentiable control  and learning,  Safe learning and control,</li>
            <li>(Inverse) optimal control, (Inverse) reinforcement learning, </li> 
            <li> Hybrid control system, Robust control, Adversarial learning</li>
        </ul>
      </div>
  </div>
</body>

<body>
  <div style="width: 100%;">
      <div style="width: 18%; height: 100px; float: left; background: transparent;"> 
         <strong>Robotics + Human</strong>
      </div>
      <div style="margin-left: 18%; height: 100px; background: transparent;"> 
          <ul>
            <li>Learning with human-on-the-loop, Human-robot teaming, </li>
            <li>Contact-rich robot manipulations, Learning from demonstrations, </li> 
            <li>Computation of cognition &amp; motor control, Task and motion planning </li>
        </ul>
      </div>
  </div>
</body>
<p>My goal is to integrate
the complementary benefits of these three disciplines to develop new theories, methods, and systems that provision efficiency, reliablity, and interactive intelligence for next-generation autonomous systems and human-robot systems.</p>

<p style="margin-bottom:0.8cm; margin-left: 0.5cm"> </p>

<hr />

<h3 id="selected-publications--submissions">Selected Publications &amp; Submissions</h3>

<p style="margin-bottom:500; margin-left: -1.0cm"> </p>

<p><img src="collections/figures/learn_lcs.gif" alt="Kitten" title="SafePDP" width="160" align="left" hspace="25" vspace="0" /></p>
<p style="margin-bottom:0.8cm; margin-left: 0.5cm"> </p>
<p><strong>Learning Linear Complementarity Systems</strong> <br />
<b>Wanxin Jin</b>, Alp Aydinoglu, Mathew Halm, and Michael Posa<br />
<em>Arixv</em>, 2021 <br />
<a href="https://arxiv.org/abs/2112.13284" target="_blank">[PDF]</a> / 
<a href="" target="_blank">[Code]</a></p>

<p style="margin-bottom:-0.4cm; margin-left: 0.5cm"> </p>

<details>
  <summary>Abstract </summary>
This paper investigates the learning, or system identification, of a class of piecewise-affine dynamical systems known as linear complementarity systems (LCSs). We propose a violation-based loss which enables efficient learning of the LCS parameterization, without prior knowledge of the hybrid mode boundaries, using gradient-based methods. The proposed violation-based loss incorporates both dynamics prediction loss and a novel complementarity - violation loss. We show several properties attained by this loss formulation, including its differentiability, the efficient computation of first- and second-order derivatives, and its relationship to the traditional prediction loss, which strictly enforces complementarity. We apply this violation-based loss formulation to learn LCSs with tens of thousands of (potentially stiff) hybrid modes. The results demonstrate a state-of-the-art ability to identify piecewise-affine dynamics, outperforming methods which must differentiate through non-smooth linear complementarity problems.
</details>

<p style="margin-bottom:1.0cm; margin-left: 0.5cm"> </p>

<p><img src="collections/figures/SafePDP.png" alt="Kitten" title="SafePDP" width="150" align="left" hspace="30" vspace="10" />
<strong>Safe Pontryagin Differentiable Programming</strong> <br />
<b>Wanxin Jin</b>, Shaoshuai Mou, and George J. Pappas<br />
<em>Advances in Neural Information Processing Systems (NeurIPS)</em>, 2021<br />
<a href="https://arxiv.org/abs/2105.14937" target="_blank">[PDF]</a> / 
<a href="https://github.com/wanxinjin/Safe-PDP" target="_blank">[Code]</a> / 
<a href="videos#SafePDP" target="_blank">[Videos]</a></p>

<p style="margin-bottom:-0.4cm; margin-left: 0.5cm"> </p>

<details>
  <summary>Abstract </summary>
We propose a Safe Pontryagin Differentiable Programming (Safe PDP) methodology, which establishes a theoretical and algorithmic framework to solve a broad class of safety-critical learning and control tasks -- problems that require the guarantee of safety constraint satisfaction at any stage of the learning and control progress. In the spirit of interior-point methods, Safe PDP handles different types of system constraints on states and inputs by incorporating them into the cost or loss through barrier functions. We prove three fundamentals of the proposed Safe PDP: first, both the solution and its gradient in the backward pass can be approximated by solving their more efficient unconstrained counterparts; second, the approximation for both the solution and its gradient can be controlled for arbitrary accuracy by a barrier parameter; and third, importantly, all intermediate results throughout the approximation and optimization strictly respect the constraints, thus guaranteeing safety throughout the entire learning and control process. We demonstrate the capabilities of Safe PDP in solving various safety-critical tasks, including safe policy optimization, safe motion planning, and learning MPCs from demonstrations, on different challenging systems such as 6-DoF maneuvering quadrotor and 6-DoF rocket powered landing.
</details>

<p style="margin-bottom:1.0cm; margin-left: 0.5cm"> </p>

<p><img src="collections/figures/lfc_v.gif" alt="Kitten" title="lfc" width="150" align="left" hspace="30" vspace="10" />
<strong>Learning from Human Directional Corrections</strong> <br />
<b>Wanxin Jin</b>, Todd D Murphey, and Shaoshuai Mou<br />
Submitted to <em>IEEE Transactions on Robotics (T-RO)</em>,    Under review <br />
<a href="https://arxiv.org/abs/2011.15014" target="_blank">[PDF]</a> /
<a href="https://github.com/wanxinjin/Learning-from-Directional-Corrections" target="_blank">[Code]</a> /
<a href="videos#LFDC" target="_blank">[Videos]</a></p>

<p style="margin-bottom:-0.4cm; margin-left: 0.5cm"> </p>
<details>
  <summary>Abstract </summary>
This paper proposes an approach which enables a robot to learn a control
objective function incrementally from human's directional corrections. Existing
methods learn from human's magnitude corrections and require a human to
carefully choose correction magnitudes, which otherwise can easily lead to
over-correction and learning inefficiency. The proposed method only requires
human's directional corrections --- corrections that only indicate the
direction of a control change without indicating its magnitude --- applied at
some time instances during the robot's motion. We only assume that each of
human's corrections, regardless of its magnitude, points in a direction that
improves the robot's current motion relative to an implicit control objective
function. Thus, human's valid corrections always account for half of the
correction space. The proposed method uses the direction of a correction to
update the estimate of the objective function based on a cutting plane
technique. We have established the theoretical results to show that this
process guarantees the convergence of the learned objective function to the
implicit one. The proposed approach has been examined by numerical examples, a
user study on two human-robot games, and a real-world quadrotor experiment. The
results confirm the convergence of the approach and show that the approach is
significantly more effective (higher success rate), efficient/effortless (less
human corrections needed), and accessible (fewer early wasted trials) than the
state-of-the-art robot interactive learning schemes.
</details>

<p style="margin-bottom:1.0cm; margin-left: 0.5cm"> </p>

<p><img src="collections/figures/lfd.png" alt="Kitten" title="SafePDP" width="150" align="left" hspace="30" vspace="10" />
<strong>Learning from Sparse Demonstrations</strong> <br />
<b>Wanxin Jin</b>, Todd D Murphey, Dana Kulic, Neta Ezer, and Shaoshuai Mou<br />
Submitted to <em>IEEE Transactions on Robotics (T-RO)</em>,   Conditionally Accepted<br />
<a href="https://arxiv.org/abs/2008.02159" target="_blank">[PDF]</a>/
<a href="https://github.com/wanxinjin/Learning-from-Sparse-Demonstrations" target="_blank">[Code]</a> /
<a href="videos#LFSD" target="_blank">[Videos]</a></p>

<p style="margin-bottom:-0.4cm; margin-left: 0.5cm"> </p>
<details>
  <summary>Abstract </summary>
This paper proposes an approach which enables a robot to learn an objective function from sparse demonstrations of an expert. The demonstrations are given by a small number of sparse waypoints; the waypoints are desired outputs of the robot's trajectory at certain time instances, sparsely located within a demonstration time horizon. The duration of the expert's demonstration may be different from the actual duration of the robot's execution. The proposed method enables to jointly learn an objective function and a time-warping function such that the robot's reproduced trajectory has minimal distance to the sparse demonstration waypoints. Unlike existing inverse reinforcement learning techniques, the proposed approach uses the differential Pontryagin's maximum principle, which allows direct minimization of the distance between the robot's trajectory and the sparse demonstration waypoints and enables simultaneous learning of an objective function and a time-warping function. We demonstrate the effectiveness of the proposed approach in various simulated scenarios. We apply the method to learn motion planning/control of a 6-DoF maneuvering unmanned aerial vehicle (UAV) and a robot arm in environments with obstacles. The results show that a robot is able to learn a valid objective function to avoid obstacles with few demonstrated waypoints.
</details>

<p style="margin-bottom:1.0cm; margin-left: 0.5cm"> </p>

<p><img src="collections/figures/PDP.png" alt="Kitten" title="SafePDP" width="150" align="left" hspace="30" vspace="20" />
<strong>Pontryagin Differentiable Programming: An End-to-End Learning and Control Framework</strong> <br />
<b>Wanxin Jin</b>, Zhaoran Wang, Zhuoran Yang, and Shaoshuai Mou<br />
<em>Advances in Neural Information Processing Systems (NeurIPS),</em>  2020 <br />
<a href="https://papers.nips.cc/paper/2020/file/5a7b238ba0f6502e5d6be14424b20ded-Paper.pdf" target="_blank">[PDF]</a> /
<a href="https://github.com/wanxinjin/Pontryagin-Differentiable-Programming" target="_blank">[Code]</a> /
<a href="videos#PDP" target="_blank">[Videos]</a></p>

<p style="margin-bottom:-0.4cm; margin-left: 0.5cm"> </p>
<details>
  <summary>Abstract </summary>
This paper develops a Pontryagin Differentiable Programming (PDP) methodology,
which establishes a unified framework to solve a broad class of learning and control
tasks. The PDP distinguishes from existing methods by two novel techniques: first,
we differentiate through Pontryaginâ€™s Maximum Principle, and this allows to obtain
the analytical derivative of a trajectory with respect to tunable parameters within an
optimal control system, enabling end-to-end learning of dynamics, policies, or/and
control objective functions; and second, we propose an auxiliary control system in
the backward pass of the PDP framework, and the output of this auxiliary control
system is the analytical derivative of the original systemâ€™s trajectory with respect
to the parameters, which can be iteratively solved using standard control tools. We
investigate three learning modes of the PDP: inverse reinforcement learning, system
identification, and control/planning. We demonstrate the capability of the PDP in
each learning mode on different high-dimensional systems, including multi-link
robot arm, 6-DoF maneuvering quadrotor, and 6-DoF rocket powered landing.
</details>

<p style="margin-bottom:1.0cm; margin-left: 0.5cm"> </p>

<p><img src="collections/figures/ioc_incomplete.png" alt="Kitten" title="SafePDP" width="150" align="left" hspace="30" vspace="30" />
<strong>Inverse Optimal Control from Incomplete Trajectory Observations</strong> <br />
<b>Wanxin Jin</b>,  Dana Kulic, Shaoshuai Mou, and Sandra Hirche <br />
<em>The International Journal of Robotics Research (IJRR),</em> 40(6-7):848â€“865,
2021 <br />
<a href="https://journals.sagepub.com/doi/full/10.1177/0278364921996384" target="_blank">[PDF]</a> /
<a href="https://github.com/wanxinjin/IOC-from-Incomplete-Trajectory-Observations" target="_blank">[Code]</a></p>

<p style="margin-bottom:-0.4cm; margin-left: 0.5cm"> </p>
<details>
  <summary>Abstract </summary>
This article develops a methodology that enables learning an objective function of an optimal control system from incomplete trajectory observations. The objective function is assumed to be a weighted sum of features (or basis functions) with unknown weights, and the observed data is a segment of a trajectory of system states and inputs. The proposed technique introduces the concept of the recovery matrix to establish the relationship between any available segment of the trajectory and the weights of given candidate features. The rank of the recovery matrix indicates whether a subset of relevant features can be found among the candidate features and the corresponding weights can be learned from the segment data. The recovery matrix can be obtained iteratively and its rank non-decreasing property shows that additional observations may contribute to the objective learning. Based on the recovery matrix, a method for using incomplete trajectory observations to learn the weights of selected features is established, and an incremental inverse optimal control algorithm is developed by automatically finding the minimal required observation. The effectiveness of the proposed method is demonstrated on a linear quadratic regulator system and a simulated robot manipulator.
</details>

<p style="margin-bottom:1.0cm; margin-left: 0.5cm"> </p>

<p><img src="collections/figures/DIOC.png" alt="Kitten" title="SafePDP" width="150" align="left" hspace="30" vspace="30" />
<strong>Distributed Inverse Optimal Control</strong> <br />
<b>Wanxin Jin</b> and Shaoshuai Mou <br />
<em>Automatica</em>, Volume 129, 2021 <br />
<a href="https://www.sciencedirect.com/science/article/abs/pii/S0005109821001783" target="_blank">[PDF]</a> /
<a href="https://github.com/ZihaoLiang/Inverse-Optimal-Control-from-Demonstration-Segments" target="_blank">[Code]</a></p>

<p style="margin-bottom:-0.4cm; margin-left: 0.5cm"> </p>
<details>
  <summary>Abstract </summary>
This paper develops a distributed approach for inverse optimal control (IOC) in multi-agent systems. Here each agent can only communicate with certain nearby neighbors and only accesses segments of systemâ€™s trajectory, which is not sufficient for the agent to solve the IOC problem alone. By introducing the concept of the data effectiveness and bridging the connection between each segment and its contribution to solving IOC, we formulate the IOC problem as a problem of achieving least-square solutions via a distributed algorithm. Simulations are provided to validate the proposed distributed IOC approach.
</details>

<p style="margin-bottom:1.0cm; margin-left: 0.5cm"> </p>

<p><img src="collections/figures/ioc_multiphase.png" alt="Kitten" title="SafePDP" width="150" align="left" hspace="30" vspace="10" />
<strong>Inverse Optimal Control for Multiphase cost functions</strong> <br />
<b>Wanxin Jin</b>, Dana Kulic, Jonathan  Lin, Shaoshuai Mou, and Sandra Hirche <br />
<em>IEEE Transactions on Robotics (T-RO)</em>, 35(6):1387â€“1398,
2019 <br />
<a href="https://ieeexplore.ieee.org/document/8778698" target="_blank">[PDF]</a> / 
<a href="https://github.com/adaptivesystemslab/ioc" target="_blank">[Code]</a></p>

<p style="margin-bottom:-0.4cm; margin-left: 0.5cm"> </p>
<details>
  <summary>Abstract </summary>
In this paper, we consider a dynamical system whose trajectory is a result of minimizing a multiphase cost function. The multiphase cost function is assumed to be a weighted sum of specified features (or basis functions) with phase-dependent weights that switch at some unknown phase transition points. A new inverse optimal control approach for recovering the cost weights of each phase and estimating the phase transition points is proposed. The key idea is to use a length-adapted window moving along the observed trajectory, where the window length is determined by finding the minimal observation length that suffices for a successful cost weight recovery. The effectiveness of the proposed method is first evaluated on a simulated robot arm, and then, demonstrated on a dataset of human participants performing a series of squatting tasks. The results demonstrate that the proposed method reliably retrieves the cost function of each phase and segments each phase of motion from the trajectory with a segmentation accuracy above 90%.
</details>

<p style="margin-bottom:1.8cm; margin-left: 0.5cm"> </p>

<hr />

<h3 id="academic-honors--awards">Academic Honors &amp; Awards</h3>

<p style="margin-bottom:100; margin-left: -1.0cm"> </p>

<ul>
  <li>Best Student Paper Finalist at IEEE 40th Digital Avionics Systems Conference (DASC) â€” 09.2021</li>
  <li>ICON Outstanding Research Awards, Purdue University â€” 04.2021</li>
  <li>Magoon Award for Excellence in Teaching, Purdue University â€” 09.2020</li>
  <li>Ross Fellowship, Purdue University â€” 2017-2018</li>
  <li>First prize winner of Provincial Science and Technology Award, Heilongjiang, China â€“ 06.2017</li>
</ul>

<p style="margin-bottom:0.8cm; margin-left: 0.5cm"> </p>

<hr />
<p><br /></p>

<div style="text-align: right"> <a href="#top">Back to top</a> </div>


    </div>

    

    

    
  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2021   Wanxin Jin.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
    
    Last updated: December 28, 2021.
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  



<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
