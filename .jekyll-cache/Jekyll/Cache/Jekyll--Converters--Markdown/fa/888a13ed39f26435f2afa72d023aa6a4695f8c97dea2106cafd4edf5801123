I"|<h2 id="project-posts">Project Posts</h2>

<p style="margin-bottom:1.5cm; margin-left: 1.5cm"> </p>
<hr />
<p style="margin-bottom:1.5cm; margin-left: 1.5cm"> </p>

<h3 id="task-driven-hybrid-model-reduction-for-dexterous-manipulation"><a href="../td_hybridreduction">Task-Driven Hybrid Model Reduction for Dexterous Manipulation</a></h3>
<p style="margin-bottom:0.5cm; margin-left: 1.5cm"> </p>

<p style="margin-bottom:0.5cm; margin-left: 0.0cm">
<img src="../blogs/TRO_HybridReduction/figures/turning_webpage2.gif" width="300" />
<img src="../blogs/TRO_HybridReduction/figures/moving_webpage2.gif" width="300" />
</p>

<p>Prepint: TBD<br />
Code: <a href="https://github.com/wanxinjin/Task-Driven-Hybrid-Reduction">https://github.com/wanxinjin/Task-Driven-Hybrid-Reduction</a><br />
Webpage: TBD</p>
<details> <summary>Abstract</summary>
 In contact-rich tasks, like dexterous manipulation, the hybrid nature of
making and breaking contact creates challenges for model representation and
control. For example, choosing and sequencing contact locations for in-hand
manipulation, where there are thousands of potential hybrid modes, is not
generally tractable. In this paper, we are inspired by the observation that far
fewer modes are actually necessary to accomplish many tasks. Building on our
prior work learning hybrid models, represented as linear complementarity
systems, we find a reduced-order hybrid model requiring only a limited number
of task-relevant modes. This simplified representation, in combination with
model predictive control, enables real-time control yet is sufficient for
achieving high performance. We demonstrate the proposed method first on
synthetic hybrid systems, reducing the mode count by multiple orders of
magnitude while achieving task performance loss of less than 5%. We also apply
the proposed method to a three-fingered robotic hand manipulating a previously
unknown object. With no prior knowledge, we achieve state-of-the-art
closed-loop performance in less than five minutes of online learning.
</details>

<p style="margin-bottom:1.5cm; margin-left: 1.5cm"> </p>
<hr />
<p style="margin-bottom:1.5cm; margin-left: 1.5cm"> </p>

<h3 id="learning-from-human-directional-corrections"><a href="../td_hybridreduction">Learning from Human Directional Corrections</a></h3>
<p style="margin-bottom:0.5cm; margin-left: 1.5cm"> </p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/Mwlwt055Tgg" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p style="margin-bottom:1.5cm; margin-left: 1.5cm"> </p>
<hr />
<p style="margin-bottom:1.5cm; margin-left: 1.5cm"> </p>

<h3 id="learning-from-human-directional-corrections-1"><a href="../td_hybridreduction">Learning from Human Directional Corrections</a></h3>
<p style="margin-bottom:0.5cm; margin-left: 1.5cm"> </p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/Mwlwt055Tgg" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

:ET